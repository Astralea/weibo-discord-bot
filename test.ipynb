{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "# from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import sqlite3\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import schedule\n",
    "import pytz\n",
    "import random\n",
    "import platform\n",
    "import uuid\n",
    "from discord_webhook import DiscordWebhook, DiscordEmbed\n",
    "from pathlib import Path\n",
    "from image_collage import combine_images, resize_gif\n",
    "\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the variables as environment variables\n",
    "WEIBO_AJAX_URL = \"https://weibo.com/ajax/statuses/mymblog?uid=6593199887&page=1&feature=0\"#os.getenv('WEIBO_AJAX_URL')\n",
    "WEIBO_URL = os.getenv('WEIBO_URL')\n",
    "MESSAGE_WEBHOOK_URL = os.getenv('MESSAGE_WEBHOOK_URL')\n",
    "STATUS_WEBHOOK_URL = os.getenv('STATUS_WEBHOOK_URL')\n",
    "\n",
    "\n",
    "class WeiboScrapper:\n",
    "    def __init__(self):\n",
    "        # Setup driver\n",
    "        # add headless\n",
    "        self.driver = self.new_driver()\n",
    "        # create a sqlite database to store id\n",
    "        # change to mongodb later\n",
    "        self.db = sqlite3.connect('weibo.db')\n",
    "        self.cursor = self.db.cursor()\n",
    "        self.cursor.execute('''CREATE TABLE IF NOT EXISTS weibo (id INTEGER PRIMARY KEY)''')\n",
    "        self.db.commit()\n",
    "        with open('kawaii_content.json', 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        self.kawaii_emojis = data['kawaii_emojis']\n",
    "        self.kawaii_texts = data['kawaii_texts']\n",
    "        self.kawaii_titles = data['kawaii_titles']\n",
    "        self.should_delete_images = True\n",
    "        # create a folder called images in the local directory if it does not exist\n",
    "        self.image_dir='images'\n",
    "        if not os.path.exists(self.image_dir):\n",
    "            os.mkdir(self.image_dir)\n",
    "\n",
    "\n",
    "    \n",
    "    def new_driver(self):\n",
    "        # Setup driver\n",
    "        # add headless\n",
    "        service = Service()\n",
    "        options = Options()\n",
    "        options.add_argument('--headless')\n",
    "        driver = webdriver.Chrome(\\\n",
    "            service=service,options=options)\n",
    "        return driver\n",
    "\n",
    "\n",
    "    def start(self):\n",
    "        # Run the scan immediately and then every 10 minutes\n",
    "        self.scan()\n",
    "        schedule.every(10).minutes.do(self.scan)\n",
    "\n",
    "        # Run send_status immediately and then every hour\n",
    "        self.send_status()\n",
    "        schedule.every(6).hours.do(self.send_status)\n",
    "\n",
    "        while True:\n",
    "            schedule.run_pending()\n",
    "            time.sleep(1)\n",
    "        \n",
    "    def get_weibo_content_once(self):\n",
    "        # check if the driver is alive\n",
    "        if self.driver.service.is_connectable():\n",
    "            pass\n",
    "        else:\n",
    "            self.driver.quit()\n",
    "            self.driver = self.new_driver()\n",
    "\n",
    "        try:\n",
    "            self.driver.get(WEIBO_AJAX_URL)\n",
    "            # Wait for the dynamic content to load\n",
    "            time.sleep(10)\n",
    "            self.driver.implicitly_wait(20)\n",
    "            pre_tag = self.driver.find_element(By.TAG_NAME, 'pre')\n",
    "            json_text = pre_tag.text\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return None\n",
    "        content = json.loads(json_text) # content is a dictionary\n",
    "        return content['data']['list']\n",
    "    \n",
    "    def check_id(self,item):\n",
    "        # if id is not in the database, return True\n",
    "        # else return False\n",
    "        weibo_item_id=item['id']\n",
    "        self.cursor.execute('''SELECT * FROM weibo WHERE id=?''',(weibo_item_id,))\n",
    "        if self.cursor.fetchone() is None:\n",
    "            #write the id to the database\n",
    "            self.cursor.execute('''INSERT INTO weibo (id) VALUES (?)''',(weibo_item_id,))\n",
    "            self.db.commit()\n",
    "            return True\n",
    "        else:\n",
    "            return False       \n",
    "\n",
    "    def get_weibo_content_loop(self):\n",
    "        i=0\n",
    "        print(f'getting weibo content... @ {datetime.now()}')\n",
    "        while True:\n",
    "            content = self.get_weibo_content_once()\n",
    "            if content:\n",
    "                break   \n",
    "            print('retrying...')\n",
    "            time.sleep(60)\n",
    "            i+=1\n",
    "            print(i)\n",
    "            if i>10:\n",
    "                print('failed')\n",
    "                return None\n",
    "        return content\n",
    "\n",
    "    def scan(self):\n",
    "        content = self.get_weibo_content_loop()\n",
    "        if content:\n",
    "            # in reverse order\n",
    "            for item in reversed(content):\n",
    "                if self.check_id(item):\n",
    "                    self.parse_item(item)\n",
    "                    time.sleep(5)\n",
    "        else:\n",
    "            print('failed to get content')\n",
    "            return None\n",
    "    \n",
    "    def image_download(self, url: str):\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            # Use uuid to generate a random file name with the same extension\n",
    "            file_name = str(uuid.uuid4()) + Path(url).suffix\n",
    "            file_path = Path('images') / file_name\n",
    "            file_path.write_bytes(response.content)\n",
    "            return file_path\n",
    "        else:\n",
    "            print(\"Unable to download image. HTTP response code:\", response.status_code)\n",
    "            return None\n",
    "\n",
    "    def images_download(self, URLs: list):\n",
    "        # Download all images in the list to the local folder ./images\n",
    "        # Return a list of local file paths\n",
    "        return [self.image_download(url) for url in URLs]\n",
    "\n",
    "    def images_delete(self, file_paths: list):\n",
    "        # Delete all images in the list\n",
    "        # Notice that file_paths could be status code\n",
    "        for file_path in file_paths:\n",
    "            if isinstance(file_path, (str, Path)):\n",
    "                try:\n",
    "                    Path(file_path).unlink()\n",
    "                except FileNotFoundError:\n",
    "                    print(f\"File {file_path} not found.\")\n",
    "\n",
    "\n",
    "    def parse_item(self,item):\n",
    "        self.webhook_message = DiscordWebhook(url=MESSAGE_WEBHOOK_URL)\n",
    "        text_raw = item['text_raw']\n",
    "        created_at = item['created_at']\n",
    "        # title=\"塔菲の新微博喵~\"\n",
    "        title = \"原神怎么你了？\"\n",
    "        source= item['source']\n",
    "        # use discord embed to display the content\n",
    "        embed_color = 16738740\n",
    "        dt = datetime.strptime(created_at, '%a %b %d %H:%M:%S %z %Y')\n",
    "        discord_timestamp = dt.timestamp()\n",
    "        # create the webhook\n",
    "        # create the embed object\n",
    "        embed = DiscordEmbed(title=title, description=text_raw, color=embed_color, url=WEIBO_URL)\n",
    "        embed.set_footer(text=f\"来自 {source}\")\n",
    "        embed.set_timestamp(discord_timestamp)\n",
    "        if 'retweeted_status' in item.keys():\n",
    "            return self.parse_item_retweet(item,embed)\n",
    "        else:\n",
    "            if 'pic_infos' in item.keys():\n",
    "                return self.parse_item_with_images(item,embed)\n",
    "            elif 'page_info' in item.keys():\n",
    "                if 'media_info' in item['page_info'].keys():\n",
    "                    return self.parse_item_with_video(item,embed)\n",
    "                else:\n",
    "                    if 'page_pic' in item['page_info'].keys():\n",
    "                        return self.parse_item_with_page_pic(item,embed)\n",
    "                    else:\n",
    "                        # write the whold item to a json file\n",
    "                        with open('item.json', 'w') as f:\n",
    "                            json.dump(item, f)\n",
    "                        raise Exception('Unknown page_info')\n",
    "            else:\n",
    "                return self.parse_item_text_only(item,embed)\n",
    "    \n",
    "    def parse_item_with_page_pic(self, item, embed):\n",
    "        image_url = item['page_info']['page_pic']\n",
    "        image_fp = self.image_download(image_url)\n",
    "        with image_fp.open('rb') as f:\n",
    "            self.webhook_message.add_file(file=f.read(), filename=image_fp.name)\n",
    "        embed.set_image(url=f'attachment://{image_fp.name}')\n",
    "        self.webhook_message.add_embed(embed)\n",
    "        response = self.webhook_message.execute()\n",
    "        if self.should_delete_images:\n",
    "            self.images_delete([image_fp])\n",
    "        return response.status_code\n",
    "\n",
    "    def parse_item_text_only(self, item, embed):\n",
    "        # add the embed object to the webhook\n",
    "        self.webhook_message.add_embed(embed)\n",
    "        # execute the webhook\n",
    "        response = self.webhook_message.execute()\n",
    "        # check the response\n",
    "        return response.status_code\n",
    "    \n",
    "    \n",
    "    def parse_item_with_images(self, item, embed):\n",
    "        image_urls = [v['original']['url'] for k,v in item['pic_infos'].items()]\n",
    "        image_filepaths = self.images_download(image_urls)\n",
    "        # use discord embed to display the content\n",
    "        # image_filenames = [os.path.basename(image_filepath) for image_filepath in image_filepaths]\n",
    "        if len(image_filepaths) == 1:\n",
    "            collage_image_path = image_filepaths[0]\n",
    "        else:\n",
    "            collage_image_path = combine_images(image_filepaths)\n",
    "        with collage_image_path.open(\"rb\") as f:\n",
    "            self.webhook_message.add_file(file=f.read(), filename=collage_image_path.name)\n",
    "        embed.set_image(url=f'attachment://{collage_image_path.name}')\n",
    "        self.webhook_message.add_embed(embed)\n",
    "        response = self.webhook_message.execute()\n",
    "        if len(image_filepaths) > 1:\n",
    "            time.sleep(1)\n",
    "            self.send_animated_images(image_filepaths)\n",
    "        if self.should_delete_images:\n",
    "            self.images_delete(image_filepaths)\n",
    "        return response.status_code\n",
    "\n",
    "    def send_animated_images(self, gif_candidates_paths):\n",
    "        # send a gif using self.webhook_message\n",
    "        # return the status code of the request\n",
    "        gif_webhook = DiscordWebhook(url=MESSAGE_WEBHOOK_URL)\n",
    "        files_to_delete = []\n",
    "        for gif in gif_candidates_paths:\n",
    "            if gif.suffix == \".gif\":\n",
    "                while gif.stat().st_size / (1024 ** 2) > 8:\n",
    "                    # If the gif is larger than 8MB, resize it\n",
    "                    gif = resize_gif(gif)\n",
    "                    files_to_delete.append(gif)\n",
    "                with gif.open(\"rb\") as f:\n",
    "                    gif_webhook.add_file(file=f.read(), filename=gif.name)\n",
    "        # execute only if there is a gif\n",
    "        if gif_webhook.files:\n",
    "            response = gif_webhook.execute()\n",
    "            if self.should_delete_images:\n",
    "                self.images_delete(files_to_delete)\n",
    "            return response.status_code\n",
    "        else:\n",
    "            return 204 # stands for no content\n",
    "         \n",
    "\n",
    "\n",
    "    def parse_item_with_video(self,item, embed):\n",
    "        video_url=item['page_info']['media_info']['stream_url']\n",
    "        video_webhook = DiscordWebhook(url=MESSAGE_WEBHOOK_URL,content=video_url)\n",
    "        self.webhook_message.add_embed(embed)\n",
    "        response1 = self.webhook_message.execute()\n",
    "        response2 = video_webhook.execute()\n",
    "        # return 200 if both requests are successful(200,204, etc., start with 2)\n",
    "        # otherwise return the status code of the first failed request\n",
    "        if response1.status_code < 300 and response2.status_code < 300:\n",
    "            return 200\n",
    "        elif response1.status_code < 300 and response2.status_code >= 300:\n",
    "            return response2.status_code\n",
    "        else:\n",
    "            return response1.status_code\n",
    "    \n",
    "    def parse_item_retweet(self,item, embed):\n",
    "        retweet_text = item['retweeted_status']['text_raw']\n",
    "        user_name=item['retweeted_status']['user']['screen_name']\n",
    "        if 'pic_infos' in item['retweeted_status'].keys():\n",
    "            image_urls=[v['original']['url'] for k,v in item['retweeted_status']['pic_infos'].items()]\n",
    "            image_filepaths = self.images_download(image_urls)\n",
    "            if len(image_filepaths) == 1:\n",
    "                collage_image_path = image_filepaths[0]\n",
    "            else:\n",
    "                collage_image_path = combine_images(image_filepaths)\n",
    "        if 'collage_image_path' in locals():\n",
    "            # add the image to embed field\n",
    "            with collage_image_path.open(\"rb\") as f:\n",
    "                self.webhook_message.add_file(file=f.read(), filename=collage_image_path.name)\n",
    "            embed.set_image(url=f'attachment://{collage_image_path.name}')\n",
    "        embed.add_embed_field(name=user_name, value=retweet_text)\n",
    "        self.webhook_message.add_embed(embed)\n",
    "        response = self.webhook_message.execute()\n",
    "        return response.status_code\n",
    "        \n",
    "\n",
    "    def send_status(self):\n",
    "        # send status to discord, say that the script is running, add some random kawaii emoji and text\n",
    "        # use discord embed to display the content\n",
    "        self.webhook_status = DiscordWebhook(url=STATUS_WEBHOOK_URL)\n",
    "        embed_color = 16738740\n",
    "        emoji = random.choice(self.kawaii_emojis)\n",
    "        text = random.choice(self.kawaii_texts)\n",
    "        title = random.choice(self.kawaii_titles)\n",
    "        if platform.system() == 'Windows':\n",
    "            machine_info = f\"{platform.node()} {platform.machine()}\"\n",
    "        else:\n",
    "            machine_info = f\"{os.uname().nodename} {os.uname().machine}\"\n",
    "        # TODO: use chatgpt to generate random text\n",
    "        # get current time, up to seconds, timezone GMT+9\n",
    "        timezone = pytz.timezone('Etc/GMT-9')\n",
    "        # Get current time up to seconds in GMT+9\n",
    "        time_now = datetime.now(timezone).strftime('%Y-%m-%d %H:%M:%S %Z')\n",
    "\n",
    "        embed = DiscordEmbed(title=title, \\\n",
    "                             description=f\"{emoji} {text} @ {time_now} -- {machine_info}\",\\\n",
    "                                  color=embed_color, \\\n",
    "                                    url=STATUS_WEBHOOK_URL)\n",
    "        embed.set_timestamp()\n",
    "        self.webhook_status.add_embed(embed)\n",
    "        # execute the webhook\n",
    "        response = self.webhook_status.execute()\n",
    "        # check the response\n",
    "        return response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting weibo content... @ 2023-08-03 18:49:40.936938\n"
     ]
    }
   ],
   "source": [
    "scraper = WeiboScrapper()\n",
    "# scraper.should_delete_images = False\n",
    "scraper.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "# find item with page_info key but without media_info key\n",
    "for i,item in enumerate(content):\n",
    "    if 'page_info' in item and 'media_info' not in item['page_info']:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://wx1.sinaimg.cn/large/007ccotFgy1hghgf13w9sj30rs0fmwi7.jpg'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[11]['page_info']['page_pic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting weibo content... @ 2023-08-03 18:22:19.791229\n"
     ]
    }
   ],
   "source": [
    "# scraper = WeiboScrapper()\n",
    "content = scraper.get_weibo_content_loop()\n",
    "\n",
    "\n",
    "# with open('weibo_content.json', 'r', encoding='utf-8') as f:\n",
    "#     content = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://wx2.sinaimg.cn/orj1080/007ccotFgy1hgbairru3tj31xg1xgkjp.jpg']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v['original']['url'] for k,v in content[2]['retweeted_status']['pic_infos'].items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'007ccotFgy1hgbairru3tj31xg1xgkjp': {'thumbnail': {'url': 'https://wx2.sinaimg.cn/wap180/007ccotFgy1hgbairru3tj31xg1xgkjp.jpg',\n",
       "   'width': 180,\n",
       "   'height': 180,\n",
       "   'cut_type': 1,\n",
       "   'type': ''},\n",
       "  'bmiddle': {'url': 'https://wx2.sinaimg.cn/wap360/007ccotFgy1hgbairru3tj31xg1xgkjp.jpg',\n",
       "   'width': 360,\n",
       "   'height': 360,\n",
       "   'cut_type': 1,\n",
       "   'type': ''},\n",
       "  'large': {'url': 'https://wx2.sinaimg.cn/orj960/007ccotFgy1hgbairru3tj31xg1xgkjp.jpg',\n",
       "   'width': 960,\n",
       "   'height': 960,\n",
       "   'cut_type': 1,\n",
       "   'type': ''},\n",
       "  'original': {'url': 'https://wx2.sinaimg.cn/orj1080/007ccotFgy1hgbairru3tj31xg1xgkjp.jpg',\n",
       "   'width': 1080,\n",
       "   'height': 1080,\n",
       "   'cut_type': 1,\n",
       "   'type': ''},\n",
       "  'largest': {'url': 'https://wx2.sinaimg.cn/large/007ccotFgy1hgbairru3tj31xg1xgkjp.jpg',\n",
       "   'width': 2048,\n",
       "   'height': 2048,\n",
       "   'cut_type': 1,\n",
       "   'type': ''},\n",
       "  'mw2000': {'url': 'https://wx2.sinaimg.cn/mw2000/007ccotFgy1hgbairru3tj31xg1xgkjp.jpg',\n",
       "   'width': 2000,\n",
       "   'height': 2000,\n",
       "   'cut_type': 1,\n",
       "   'type': ''},\n",
       "  'focus_point': {'left': 0, 'top': 0, 'width': 1, 'height': 1},\n",
       "  'object_id': '1042018:16067de9a4357f8b48ffeb17b779d500',\n",
       "  'pic_id': '007ccotFgy1hgbairru3tj31xg1xgkjp',\n",
       "  'photo_tag': 0,\n",
       "  'type': 'pic',\n",
       "  'pic_status': 0}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[2]['retweeted_status']['pic_infos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper.parse_item(content[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,item in enumerate(content):\n",
    "    print(i,item['text_raw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper.should_delete_images = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper.parse_item(content[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper = WeiboScrapper()\n",
    "response=scraper.parse_item(content[7])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content[7]['retweeted_status']['user']['screen_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save content to a file\n",
    "import json\n",
    "with open('weibo_content.json', 'w') as f:\n",
    "    json.dump(content, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "for i,item in enumerate(content):\n",
    "    if 'retweeted_status' in item:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
